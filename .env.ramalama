OPENAI_BASE_URL=http://localhost:8080/v1
OPENAI_API_KEY=unused
# RamaLama cannot currently run multiple models on the same port. So, if you
# want to run 07-eval, set CHAT_MODEL to EVAL_MODEL's value.
# See https://github.com/containers/ramalama/issues/598 for more.
CHAT_MODEL=qwen2.5:0.5b
EVAL_MODEL=deepseek-r1:14b

OTEL_SERVICE_NAME=testing-genai
# Change to 'false' to hide prompt and completion content
OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=true
# Change to affect behavior of which resources are detected. Note: these
# choices are specific to the language, in this case Python.
OTEL_EXPERIMENTAL_RESOURCE_DETECTORS=process_runtime,os,otel,telemetry_distro

# Export metrics every 3 seconds instead of every minute
OTEL_METRIC_EXPORT_INTERVAL=3000
# Export traces every 3 seconds instead of every 5 seconds
OTEL_BSP_SCHEDULE_DELAY=3000
