OPENAI_BASE_URL=http://localhost:8080/v1
OPENAI_API_KEY=unused
# RamaLama cannot currently run multiple models on the same port. So, if you
# want to run 07-eval, set CHAT_MODEL to EVAL_MODEL's value.
# See https://github.com/containers/ramalama/issues/598 for more.
CHAT_MODEL=gemma3:1b
# Eval model must be able larger, to not itself hallucinate when judging
# responses. It must support tool detection, but not necessarily tool use.
EVAL_MODEL=michaelneale/deepseek-r1-goose

OTEL_SERVICE_NAME=testing-genai
# Change to 'false' to hide prompt and completion content
OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=true
# Disable resource detectors by default
OTEL_PYTHON_DISABLED_RESOURCE_DETECTORS=all

# Export metrics every 3 seconds instead of every minute
OTEL_METRIC_EXPORT_INTERVAL=3000
# Export traces every 3 seconds instead of every 5 seconds
OTEL_BSP_SCHEDULE_DELAY=3000
